# Пайплайн CEFR для казахско‑русских текстов

Проект решает задачу оценки сложности текста (CEFR A1–C2) для казахского языка по параллельному переводу на русский. Пайплайн включает перевод, выравнивание слов/фраз, сопоставление с уровнем CEFR и агрегацию на уровне текста. Дополнительно можно обучить классификатор для словарного уровня CEFR, а также текстовый классификатор по английско‑русскому параллельному корпусу.

## Как быстро начать

### 1. Установка окружения
**Conda (рекомендуется):**
```bash
conda env create -f environment.yml
conda activate kazakh_cefr_env
```

**pip / venv:**
```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Загрузка параллельного корпуса KazParC
```bash
python -m cefr.data.download
```
Команда сохранит файл `data/parallel/kazparc_kz_ru.csv` и вернет путь к нему.

### 3. Построение «серебряных» CEFR-меток
```bash
python -m cefr.data.silver
```
В результате появится файл `data/labels/silver_word_labels.csv` с парами «казахская фраза → русский перевод → уровень CEFR».

### 4. Прогон пайплайна через CLI
```bash
python run_pipeline.py --text_kz "Ол кітап оқып жатыр"
```
При желании можно передать готовый перевод и миновать автоматический перевод:

```bash
python run_pipeline.py --text_kz "Ол кітап оқып жатыр" --text_ru "Он читает книгу"
```
На выходе: перевод (или переданный перевод), распределение уровней CEFR и список выровненных фраз.

### 5. Jupyter-ноутбук
В папке `notebooks/` создайте (или обновите) файл `cefr_pipeline_demo.ipynb` содержимым из `main.ipynb`. Ноутбук выполняет все шаги пайплайна в среде Colab/Kaggle или локально, используя GPU при наличии.

## Что происходит внутри

1. **Перевод** — `cefr/translation.py` оборачивает модель `issai/tilmash` и кэширует пайплайн.
2. **Выранивание** — `cefr/alignment.py` формирует взаимные соответствия слов через `EmbeddingAligner` и предоставляет диагностические метрики.
3. **Сборка фраз** — функция `merge_kz_to_single_ru` из `cefr/alignment.py` объединяет соседние казахские токены, выровненные с одним русским словом.
4. **Пайплайн** — `cefr/pipeline.py` реализует `TextPipeline` и `EnsemblePipeline`, которые объединяют перевод, выравнивание и скоринг CEFR.
5. **Работа с ресурсами** — `cefr/data.py` лениво загружает словарь «русское слово → уровень CEFR».
6. **Лингвистические признаки** — `cefr/text_features.py` вычисляет длину предложений, количество токенов/типов, соотношение type/token, долю длинных слов, число слогов и другие показатели для каждого текста.
7. **Серебряные метки** — `cefr/data/silver.py` строит набор слабых меток по параллельному корпусу, дополнительно приводя русские слова к нормальной форме через `pymorphy3`.
8. **Текстовый классификатор** — `cefr/training/text_classification.py` объединяет TF-IDF по английскому и русскому текстам с лингвистическими признаками и обучает логистическую регрессию.

## Настройка и GPU

- Все модули автоматически переходят на CUDA, если `torch.cuda.is_available()` возвращает `True`. При необходимости можно явно передать `device="cuda"` в `EmbeddingAligner` и `get_translator`.
- Длинные предложения автоматически пропускаются с предупреждением, чтобы избежать превышения лимита в 512 токенов у BERT.

## Обучение и дообучение

1. **Выравнивание (awesome-align)**  
   - Сформируйте файл `data/parallel/train.kazru` с строками вида `kazakh ||| russian`.  
   - Запустите  
     ```bash
     bash scripts/train_align.sh
     bash scripts/align_infer.sh
     ```  
     Это улучшит качество выравнивания и, как следствие, точность CEFR-оценки.

2. **Эксперименты**  
   - Увеличьте размер русско-CEFR словаря (`data/cefr/russian_cefr_sample.csv`), заменив его на собственный большой список.  
   - Настройте параметры в `config/default.yaml` (модель переводчика, устройство, слой и порог выравнивания, вес русского классификатора).  
   - Добавьте собственные метрики и отчеты, интегрировав функции из `cefr.pipeline` в ваш продукт.

3. **Текстовая классификация CEFR**  
   - В папке `data/text/` хранятся корпуса `cefr_leveled_texts.csv` и `en_ru_cefr_corpus.csv`; второй файл содержит ~1500 английских текстов, их переводы на русский и целевые уровни CEFR.  
   - Лингвистические признаки (число предложений, токенов, типов, слогов и доля длинных слов) вычисляются автоматически в `cefr/text_features.py` и подмешиваются к TF-IDF.  
   - Выполните
     ```bash
     python -m cefr.training.text_classification --output-dir models/en_ru_text_classifier
     ```
     чтобы обучить базовый логистический классификатор на TF-IDF и лингвистических признаках.  
   - В отчете `text_classifier_metrics.json` сохранены метрики, распределение классов и confusion matrix для последующего анализа.

## Структура проекта

```
data/
  cefr/                        # словари CEFR
  parallel/                    # параллельные корпуса
  labels/                      # сгенерированные серебряные метки
models/
notebooks/
  cefr_pipeline_demo.ipynb     # jupyter-скрипт для полного пайплайна
scripts/
  train_align.sh               # обучение awesome-align
  align_infer.sh               # применение выравнителя
cefr/
  alignment.py                 # выравнивание и диагностика
  config.py                    # датаклассы и YAML-конфиг
  data/__init__.py             # словари CEFR
  data/download.py             # загрузка KazParC
  data/silver.py               # генерация «серебряных» меток
  models/                      # модель русских предложений
  notebook.py                  # утилиты для ноутбуков
  pipeline.py                  # TextPipeline и EnsemblePipeline
  text_features.py             # извлечение лингвистических признаков текста
  training/                    # обучение табличного и текстового классификаторов
  training/tabular.py          # табличный классификатор + CLI
  training/text_classification.py  # текстовый классификатор + CLI
config/default.yaml            # настройки по умолчанию
run_pipeline.py                # CLI-пример
tests/                         # smoke-тесты
```

## Что можно улучшить

- **Расширение корпусов** — подключите дополнительные параллельные источники или собственные наборы данных.
- **Собственные словари** — обогащайте русско-CEFR словарь полноразмерными леммами или вручную размеченными данными.
- **Автовalidation** — добавьте pytest с моками для сервисов (`TranslationService`, `AlignmentService`) и интеграционные тесты для пайплайна.
- **Интерфейс** — заверните `TextCefrPipeline` в REST/CLI-сервис или интерфейс на Streamlit/Gradio.

## Лицензия

Проект предназначен для исследовательских целей. Соблюдайте лицензии используемых моделей, датасетов и внешних сервисов.
