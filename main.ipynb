{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47127dc",
   "metadata": {},
   "source": [
    "# Kazakh CEFR Exploration\n",
    "\n",
    "This notebook walks through the core components of the Kazakh↔Russian CEFR project: data preparation, alignment diagnostics, text-level prediction, and a tabular sentence classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68adedca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/zhantore/Documents/cefr-classification-kk\n",
      "Python version: 3.10.19\n",
      "PyTorch version: 2.7.1\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import platform\n",
    "import torch\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path.cwd()\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Python version: {platform.python_version()}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d04bcf",
   "metadata": {},
   "source": [
    "## Prepare Shared Resources\n",
    "\n",
    "We cache the parallel KazParC slice and the derived silver labels. The helper functions regenerate artifacts only when they are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e14942ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kazakh_cefr_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing parallel corpus: data/parallel/kazparc_kz_ru.csv\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'alignment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing existing parallel corpus: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPARALLEL_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m custom_aligner \u001b[38;5;241m=\u001b[39m EmbeddingAligner(\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malignment\u001b[49m)\n\u001b[1;32m     28\u001b[0m SILVER_PATH \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/labels/silver_word_labels.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SILVER_PATH\u001b[38;5;241m.\u001b[39mexists():\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'alignment'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "from cefr import load_config\n",
    "import cefr.alignment as alignment_mod\n",
    "from cefr.data.download import save_kz_ru\n",
    "from cefr.data.silver import build_silver_labels\n",
    "\n",
    "alignment_mod = importlib.reload(alignment_mod)\n",
    "EmbeddingAligner = alignment_mod.EmbeddingAligner\n",
    "\n",
    "cfg = load_config()\n",
    "\n",
    "PARALLEL_PATH = Path('data/parallel/kazparc_kz_ru.csv')\n",
    "if not PARALLEL_PATH.exists():\n",
    "    PARALLEL_PATH = Path(\n",
    "        save_kz_ru(\n",
    "            split='train[:2000]',\n",
    "            out_dir='data/parallel',\n",
    "            out_name='kazparc_kz_ru.csv',\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(f\"Using existing parallel corpus: {PARALLEL_PATH}\")\n",
    "\n",
    "custom_aligner = EmbeddingAligner(cfg.pipeline.alignment)\n",
    "\n",
    "SILVER_PATH = Path('data/labels/silver_word_labels.csv')\n",
    "if not SILVER_PATH.exists():\n",
    "    SILVER_PATH = build_silver_labels(\n",
    "        parallel_csv=PARALLEL_PATH,\n",
    "        rus_cefr=cfg.pipeline.russian_cefr_path,\n",
    "        out_csv=SILVER_PATH,\n",
    "        aligner=custom_aligner,\n",
    "    )\n",
    "print(f\"Silver labels: {SILVER_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17074f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed99e61c",
   "metadata": {},
   "source": [
    "## Silver Label Overview\n",
    "\n",
    "Inspect the automatically generated token-level labels and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f148c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 18,485\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kaz_item</th>\n",
       "      <th>rus_item</th>\n",
       "      <th>cefr</th>\n",
       "      <th>kaz_sent</th>\n",
       "      <th>rus_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>кезінде</td>\n",
       "      <td>При</td>\n",
       "      <td>B1</td>\n",
       "      <td>Қауіпті қалдықтар трансшекаралық тасымалдау ке...</td>\n",
       "      <td>При трансграничной перевозке опасные отходы до...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>трансшекаралық</td>\n",
       "      <td>трансграничной</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Қауіпті қалдықтар трансшекаралық тасымалдау ке...</td>\n",
       "      <td>При трансграничной перевозке опасные отходы до...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>тасымалдау</td>\n",
       "      <td>перевозке</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Қауіпті қалдықтар трансшекаралық тасымалдау ке...</td>\n",
       "      <td>При трансграничной перевозке опасные отходы до...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Қауіпті</td>\n",
       "      <td>опасные</td>\n",
       "      <td>B2</td>\n",
       "      <td>Қауіпті қалдықтар трансшекаралық тасымалдау ке...</td>\n",
       "      <td>При трансграничной перевозке опасные отходы до...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>қалдықтар</td>\n",
       "      <td>отходы</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Қауіпті қалдықтар трансшекаралық тасымалдау ке...</td>\n",
       "      <td>При трансграничной перевозке опасные отходы до...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         kaz_item        rus_item     cefr  \\\n",
       "0         кезінде             При       B1   \n",
       "1  трансшекаралық  трансграничной  Unknown   \n",
       "2      тасымалдау       перевозке  Unknown   \n",
       "3         Қауіпті         опасные       B2   \n",
       "4       қалдықтар          отходы  Unknown   \n",
       "\n",
       "                                            kaz_sent  \\\n",
       "0  Қауіпті қалдықтар трансшекаралық тасымалдау ке...   \n",
       "1  Қауіпті қалдықтар трансшекаралық тасымалдау ке...   \n",
       "2  Қауіпті қалдықтар трансшекаралық тасымалдау ке...   \n",
       "3  Қауіпті қалдықтар трансшекаралық тасымалдау ке...   \n",
       "4  Қауіпті қалдықтар трансшекаралық тасымалдау ке...   \n",
       "\n",
       "                                            rus_sent  \n",
       "0  При трансграничной перевозке опасные отходы до...  \n",
       "1  При трансграничной перевозке опасные отходы до...  \n",
       "2  При трансграничной перевозке опасные отходы до...  \n",
       "3  При трансграничной перевозке опасные отходы до...  \n",
       "4  При трансграничной перевозке опасные отходы до...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "silver_df = pd.read_csv(SILVER_PATH)\n",
    "print(f\"Rows: {len(silver_df):,}\")\n",
    "silver_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e162d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cefr\n",
       "A1         2028\n",
       "A2         2104\n",
       "B1         2795\n",
       "B2         2039\n",
       "C1         1618\n",
       "C2         1209\n",
       "Unknown    6692\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silver_df['cefr'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edba44f",
   "metadata": {},
   "source": [
    "## Alignment Diagnostics\n",
    "\n",
    "Grab a sample sentence pair and review the informative alignments along with probability-based heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "646ac2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kaz_index</th>\n",
       "      <th>kaz_token</th>\n",
       "      <th>rus_index</th>\n",
       "      <th>rus_token</th>\n",
       "      <th>joint_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Айнымас</td>\n",
       "      <td>2</td>\n",
       "      <td>верные</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>принциптерге</td>\n",
       "      <td>3</td>\n",
       "      <td>принципы</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>және</td>\n",
       "      <td>4</td>\n",
       "      <td>и</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>өзіңнің</td>\n",
       "      <td>7</td>\n",
       "      <td>своей</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>жеке</td>\n",
       "      <td>8</td>\n",
       "      <td>личной</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>миссияңнан</td>\n",
       "      <td>9</td>\n",
       "      <td>миссии</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>ауытқымау</td>\n",
       "      <td>5</td>\n",
       "      <td>сосредоточенность</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>таңдау</td>\n",
       "      <td>16</td>\n",
       "      <td>выбор</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>жасауға</td>\n",
       "      <td>14</td>\n",
       "      <td>сделать</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>көмектесетін</td>\n",
       "      <td>13</td>\n",
       "      <td>помогающей</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>ақыл</td>\n",
       "      <td>12</td>\n",
       "      <td>мудростью,</td>\n",
       "      <td>0.998848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>қосады.</td>\n",
       "      <td>10</td>\n",
       "      <td>наделяют</td>\n",
       "      <td>0.999949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    kaz_index     kaz_token  rus_index          rus_token  joint_prob\n",
       "0           0       Айнымас          2             верные    1.000000\n",
       "1           1  принциптерге          3           принципы    1.000000\n",
       "2           3          және          4                  и    1.000000\n",
       "3           4       өзіңнің          7              своей    1.000000\n",
       "4           5          жеке          8             личной    1.000000\n",
       "5           6    миссияңнан          9             миссии    1.000000\n",
       "6           7     ауытқымау          5  сосредоточенность    1.000000\n",
       "7           9        таңдау         16              выбор    1.000000\n",
       "8          10       жасауға         14            сделать    1.000000\n",
       "9          11  көмектесетін         13         помогающей    1.000000\n",
       "10         12          ақыл         12         мудростью,    0.998848\n",
       "11         13       қосады.         10           наделяют    0.999949"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cefr.alignment import (\n",
    "    fraction_above_threshold,\n",
    "    informative_link_share,\n",
    "    is_informative,\n",
    ")\n",
    "\n",
    "sample = silver_df.sample(random_state=42).iloc[0]\n",
    "kz_words = tuple(sample['kaz_sent'].split())\n",
    "ru_words = tuple(sample['rus_sent'].split())\n",
    "\n",
    "details = custom_aligner.diagnostics(\n",
    "    kz_words,\n",
    "    ru_words,\n",
    "    layer=cfg.pipeline.alignment.layer,\n",
    "    threshold=cfg.pipeline.alignment.threshold,\n",
    ")\n",
    "details_matrix = details.to_dataframe(kz_words, ru_words)\n",
    "\n",
    "true_links = (\n",
    "    details_matrix[details_matrix['is_link']]\n",
    "    .copy()\n",
    "    .assign(\n",
    "        is_informative_pair=lambda df: df['kaz_token'].apply(is_informative)\n",
    "        & df['rus_token'].apply(is_informative)\n",
    "    )\n",
    "    .sort_values(['kaz_index', 'rus_index'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "true_links.drop(['is_link', 'is_informative_pair', 'p_ru_given_kz', 'p_kz_given_ru'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba551ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informative link share: 1.000\n",
      "Fraction above 0.80 threshold on sample: 0.929\n"
     ]
    }
   ],
   "source": [
    "share_correct = informative_link_share(details, kz_words, ru_words)\n",
    "prob_threshold = 0.8\n",
    "population_size = len(silver_df)\n",
    "sample_size = min(200, population_size)\n",
    "if sample_size == 0:\n",
    "    sample_records = []\n",
    "else:\n",
    "    sample_records = silver_df.sample(n=sample_size, random_state=1)[['kaz_sent', 'rus_sent']].to_dict('records')\n",
    "\n",
    "coverage = fraction_above_threshold(\n",
    "    sample_records,\n",
    "    custom_aligner,\n",
    "    layer=cfg.pipeline.alignment.layer,\n",
    "    thresh=cfg.pipeline.alignment.threshold,\n",
    "    prob_threshold=prob_threshold,\n",
    ")\n",
    "\n",
    "print(f\"Informative link share: {share_correct:.3f}\")\n",
    "print(f\"Fraction above {prob_threshold:.2f} threshold on sample: {coverage:.3f}\")\n",
    "\n",
    "#TODO:  Сгенерировать таблицу после предсказаний\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d1fb51",
   "metadata": {},
   "source": [
    "## Tabular CEFR Classifier\n",
    "\n",
    "Load the sklearn pipeline trained on `data/text/kazparc_kz_ru_cefr_estimated.csv` and review sample predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e38c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi!\\nI've been meaning to write for ages and f...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿It was not so much how hard people found the ...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keith recently came back from a trip to Chicag...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Griffith Observatory is a planetarium, and...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-LRB- The Hollywood Reporter -RRB- It's offici...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>Light propagating in the vicinity of astrophys...</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>Future of dentistry has become one of the most...</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>﻿The forests – and suburbs – of Europe are ech...</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>Hedge funds are turning bullish on oil once ag...</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>Without additional heating, radiative cooling ...</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label\n",
       "0     Hi!\\nI've been meaning to write for ages and f...    B2\n",
       "1     ﻿It was not so much how hard people found the ...    B2\n",
       "2     Keith recently came back from a trip to Chicag...    B2\n",
       "3     The Griffith Observatory is a planetarium, and...    B2\n",
       "4     -LRB- The Hollywood Reporter -RRB- It's offici...    B2\n",
       "...                                                 ...   ...\n",
       "1489  Light propagating in the vicinity of astrophys...    C2\n",
       "1490  Future of dentistry has become one of the most...    C2\n",
       "1491  ﻿The forests – and suburbs – of Europe are ech...    C2\n",
       "1492  Hedge funds are turning bullish on oil once ag...    C2\n",
       "1493  Without additional heating, radiative cooling ...    C2\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/text/cefr_leveled_texts.csv')\n",
    "\n",
    "# TODO: Найти источники для обоснования feature extraction process\n",
    "\n",
    "\n",
    "# score = (\n",
    "#     0.13 * nf[\"nf_avg_sent_len\"]\n",
    "#     + 0.82 * nf[\"nf_avg_word_len\"]\n",
    "#     + 0.01 * nf[\"nf_ttr\"]\n",
    "#     + 0.20 * nf[\"nf_long_ratio\"]\n",
    "#     + 0.05 * nf[\"nf_char_len\"]\n",
    "#     + 0.05 * nf[\"nf_align_diff\"]\n",
    "# ).astype(float)\n",
    "\n",
    "# Source\n",
    "# The texts are taken from free resources found online including: The British Council, ESLFast, and the cnn-dailymail dataset.\n",
    "# Texts that were found without a label were labelled using Text Inspector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adc52a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.860\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kaz</th>\n",
       "      <th>rus</th>\n",
       "      <th>true_cefr</th>\n",
       "      <th>pred_cefr</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Маған бұдан былай жақсартудың қажеті жоқ.</td>\n",
       "      <td>Мне больше не нужно совершенствоваться.</td>\n",
       "      <td>A2</td>\n",
       "      <td>A2</td>\n",
       "      <td>0.798754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Бірақ басшылардың бірде-бірі жұмыс орнында жоқ.</td>\n",
       "      <td>Но ни одного из руководителей нет на рабочем м...</td>\n",
       "      <td>A2</td>\n",
       "      <td>A2</td>\n",
       "      <td>0.778494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Мұндай жағдайға әлемдік тарихтағы екі қасіретт...</td>\n",
       "      <td>Первые подобные случаи являются следствием дву...</td>\n",
       "      <td>C1</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.728524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Бұл әрекеті қазір әлеуметтік желіде желдей есі...</td>\n",
       "      <td>Эта акция сейчас распространяется в социальных...</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.614697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Бірқатар өңірлер оның зардабын қатты тартуда.</td>\n",
       "      <td>Целый ряд регионов испытывает в ней острую пот...</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.760007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 kaz  \\\n",
       "0          Маған бұдан былай жақсартудың қажеті жоқ.   \n",
       "1    Бірақ басшылардың бірде-бірі жұмыс орнында жоқ.   \n",
       "2  Мұндай жағдайға әлемдік тарихтағы екі қасіретт...   \n",
       "3  Бұл әрекеті қазір әлеуметтік желіде желдей есі...   \n",
       "4      Бірқатар өңірлер оның зардабын қатты тартуда.   \n",
       "\n",
       "                                                 rus true_cefr pred_cefr  \\\n",
       "0            Мне больше не нужно совершенствоваться.        A2        A2   \n",
       "1  Но ни одного из руководителей нет на рабочем м...        A2        A2   \n",
       "2  Первые подобные случаи являются следствием дву...        C1        C1   \n",
       "3  Эта акция сейчас распространяется в социальных...        B2        B2   \n",
       "4  Целый ряд регионов испытывает в ней острую пот...        B2        B2   \n",
       "\n",
       "   confidence  \n",
       "0    0.798754  \n",
       "1    0.778494  \n",
       "2    0.728524  \n",
       "3    0.614697  \n",
       "4    0.760007  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from joblib import load\n",
    "import pandas as pd\n",
    "from cefr.training import TabularTrainingConfig, train_tabular_model\n",
    "\n",
    "MODEL_DIR = Path('models/kazparc_tabular_cefr')\n",
    "MODEL_PATH = MODEL_DIR / 'model.joblib'\n",
    "METRICS_PATH = MODEL_DIR / 'metrics.json'\n",
    "DATA_PATH = Path('data/text/kazparc_kz_ru_cefr_estimated.csv')\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    print(f\"Tabular training dataset not found at {DATA_PATH}. Skipping tabular classifier section.\")\n",
    "    tabular_result = None\n",
    "else:\n",
    "    if not MODEL_PATH.exists():\n",
    "        tabular_cfg = TabularTrainingConfig(train_path=DATA_PATH, output_dir=MODEL_DIR)\n",
    "        train_tabular_model(tabular_cfg)\n",
    "\n",
    "    classifier = load(MODEL_PATH)\n",
    "    metrics = json.loads(METRICS_PATH.read_text()) if METRICS_PATH.exists() else None\n",
    "    kazparc_df = pd.read_csv(DATA_PATH)\n",
    "    feature_columns = [\n",
    "        col for col in kazparc_df.columns if col not in {'predicted_cefr', 'predicted_cefr_int'}\n",
    "    ]\n",
    "\n",
    "    if metrics:\n",
    "        print(f\"Validation accuracy: {metrics['accuracy']:.3f}\")\n",
    "\n",
    "    sample = kazparc_df.sample(n=5, random_state=0)\n",
    "    proba = classifier.predict_proba(sample[feature_columns])\n",
    "    preds = classifier.predict(sample[feature_columns])\n",
    "    confidence = proba.max(axis=1)\n",
    "\n",
    "    tabular_result = pd.DataFrame({\n",
    "        'kaz': sample['kaz'].values,\n",
    "        'rus': sample['rus'].values,\n",
    "        'true_cefr': sample['predicted_cefr'].values,\n",
    "        'pred_cefr': preds,\n",
    "        'confidence': confidence,\n",
    "    })\n",
    "\n",
    "if 'tabular_result' in locals() and tabular_result is not None:\n",
    "    tabular_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dafb02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d11a523a",
   "metadata": {},
   "source": [
    "\n",
    "## Train CEFR Text Classifier\n",
    "\n",
    "With the bilingual corpus prepared, we can train the CEFR text classifier that combines TF-IDF features with the linguistic statistics computed earlier. The helper below wraps the `cefr.training.text_classification` module so training can run directly from this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d959bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from cefr.training.text_classification import parse_args, train_text_classifier\n",
    "\n",
    "TEXT_CLASSIFIER_DIR = Path(\"models/en_ru_text_classifier\")\n",
    "TEXT_CLASSIFIER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "classifier_config = parse_args([\n",
    "    \"--dataset-path\", str(OUTPUT_CSV),\n",
    "    \"--output-dir\", str(TEXT_CLASSIFIER_DIR),\n",
    "    \"--test-size\", \"0.2\",\n",
    "    \"--random-state\", \"42\",\n",
    "])\n",
    "\n",
    "training_result = train_text_classifier(classifier_config)\n",
    "training_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c24479",
   "metadata": {},
   "source": [
    "\n",
    "### Inspect Metrics\n",
    "\n",
    "The training routine stores metrics alongside the fitted pipeline. Loading the JSON report provides overall accuracy, per-level precision/recall, and the confusion matrix so we can inspect model performance without leaving the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eff70cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "metrics_path = Path(training_result[\"metrics_path\"])\n",
    "with metrics_path.open(encoding=\"utf-8\") as handle:\n",
    "    metrics = json.load(handle)\n",
    "\n",
    "display({\n",
    "    \"accuracy\": metrics.get(\"accuracy\"),\n",
    "    \"labels\": metrics.get(\"labels\"),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848ec112",
   "metadata": {},
   "source": [
    "\n",
    "### Quick Inference Helper\n",
    "\n",
    "Load the persisted classifier and run predictions on fresh samples. Provide both English text and an optional Russian translation; the model will output the predicted CEFR level together with class probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18544fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "\n",
    "model_path = Path(training_result[\"model_path\"])\n",
    "text_classifier = load(model_path)\n",
    "\n",
    "sample_rows = pd.DataFrame([\n",
    "    {\n",
    "        \"text_en\": \"The industrial revolution transformed many European countries in the 19th century.\",\n",
    "        \"text_ru\": \"Промышленная революция преобразила многие европейские страны в XIX веке.\",\n",
    "    },\n",
    "])\n",
    "\n",
    "predicted_levels = text_classifier.predict(sample_rows)\n",
    "probabilities = text_classifier.predict_proba(sample_rows)\n",
    "list(zip(predicted_levels, probabilities))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kazakh_cefr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
